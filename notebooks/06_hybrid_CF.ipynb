{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2750c1c",
   "metadata": {},
   "source": [
    "# <u> Hybrid Content-Collaborative Filtering Model</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10c92a",
   "metadata": {},
   "source": [
    "Building on the collaborative filtering approaches explored in previous notebooks, **hybrid content-collaborative filtering** extends the Funk SVD model by incorporating content features as an additive component on top of the purely collaborative prediction explored in the model-based CB. The goal is not to replace collaborative signals, but to correct and enrich them, especially in cold or sparse regimes, while preserving the strong performance of matrix factorization in warm-start settings early observed.\n",
    "\n",
    "**<u>Predictions:</u>**\n",
    "\n",
    "The predicted rating for a user $u$ on an item $i$ is defined as:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\mu + b_u + b_i + \\mathbf{p}_u^\\top \\mathbf{q}_i \n",
    "+ \\mathbf{w}_u^\\top \\mathbf{x}_u + \\mathbf{w}_i^\\top \\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where:\n",
    "- The first part of the equation corresponds to the Funk SVD model, where $\\mu$ denotes the global mean rating and $b_u$ and $b_i$ are user and item bias terms. The vectors $\\mathbf{p}_u$ and $\\mathbf{q}_i$ represent the latent user and item embeddings learned from interaction data.\n",
    "- The additional terms introduce content-based corrections. The vectors $\\mathbf{x}_u \\in \\mathbb{R}^{d_u}$ and $\\mathbf{x}_i \\in \\mathbb{R}^{d_i}$ denote user and item content features, respectively, while $\\mathbf{w}_u$ and $\\mathbf{w}_i$ are learned linear weights mapping these features directly to rating adjustments.\n",
    "\n",
    "**<u>Training and Iterative Updates:</u>**\n",
    "\n",
    "During training, the model jointly learns the latent factors, bias terms, and content feature weights by minimizing a regularized squared error over observed ratings:\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{P}, \\mathbf{Q}, \\mathbf{w}_u, \\mathbf{w}_i, \\mathbf{b}}\n",
    "\\sum_{(u,i) \\in \\mathcal{K}}\n",
    "\\left(r_{u,i} - \\hat{r}_{u,i}\\right)^2\n",
    "+ \\lambda \\left(\n",
    "\\|\\mathbf{P}\\|^2 + \\|\\mathbf{Q}\\|^2 + \\|\\mathbf{w}_u\\|^2 + \\|\\mathbf{w}_i\\|^2 + \\|\\mathbf{b}\\|^2\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $\\mathcal{K}$ denotes the set of observed user–item interactions in the training data and $\\lambda$ controls the strength of regularization.\n",
    "\n",
    "The optimization follows the same iterative procedure as Funk SVD and is performed using the  Stochastic Gradient Descent. This ensures a consistent training and comparative setup, while allowing content-based signals to be incorporated with minimal additional complexity.\n",
    "\n",
    "**<u>Hyperparameter Selection:</u>**\n",
    "\n",
    "The main hyperparameters evaluated on the validation set are:\n",
    "\n",
    "- Number of latent factors, controlling the capacity of the collaborative component;  \n",
    "- Regularization parameter, applied uniformly across all learned parameters;  \n",
    "- Learning rate, governing the optimization dynamics;  \n",
    "- Number of epochs, determining the number of full passes over the training data.\n",
    "\n",
    "**<u>Implementation:</u>**\n",
    "\n",
    "Due to the absence of a pre-built library supporting this specific additive hybrid formulation, the model is implemented using a custom PyTorch architecture. This approach enables direct control over the loss function and optimization process, while extending the original Funk SVD implementation in a minimal and transparent manner. Existing libraries such as Surprise (SVD++) and LightFM do not align with these requirements, as the former does not support explicit content features and the latter focuses on implicit feedback with ranking-based objectives rather than explicit rating prediction with an MSE loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546584e",
   "metadata": {},
   "source": [
    "## <u>0. Setting:</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19871441",
   "metadata": {},
   "source": [
    "### <u>0.1 Import libraries</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6863777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd, numpy as np, os, sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Remove userwarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# Set the working directory\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom modules\n",
    "from modules.hybrid_CFF import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da808f29",
   "metadata": {},
   "source": [
    "### <u>0.2 Import pre-built datasets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8427c02",
   "metadata": {},
   "source": [
    "For consistency with the previous experiments, we adopt the same **time-based train–validation–test split**. For each user, the **earliest 70% of ratings** are used for training, the **next 10% for validation**, and the **most recent 20% for testing**. This ensures a fair comparison across models while preventing information leakage into the evaluation set.\n",
    "\n",
    "Given the hybrid nature of the hybrid algorithm, which jointly leverages **collaborative interactions and content-based features**, the movie feature vectors constructed in `05_content_F.ipynb` are used as item-information. In addition, user-specific feature representations are constructed and incorporated into the model. This allows the model to learn latent representations that combine interaction patterns with explicit content information in opposite to its baseline model evalauated in `04_model_CF.ipynb`.\n",
    "\n",
    "Following the evaluation protocol used for collaborative and model-based approaches, RMSE is reported on the full test set as well as separately for **warm-start** and **cold-start** settings. The cold-start subset corresponds to movies with fewer than 10 interactions in the training set, where predictions rely more heavily on content features rather than collaborative signals. Additionally, Hyperparameter tuning is performed on the validation set, and the total training and evaluation time is reported to enable computational performance comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40108a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe over the columns of interest\n",
    "train_df = pd.read_csv('../data/processed/train_df.csv')\n",
    "val_df = pd.read_csv('../data/processed/val_df.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_df.csv')\n",
    "warm_test_df = pd.read_csv('../data/processed/warm_test_df.csv')\n",
    "cold_test_df = pd.read_csv('../data/processed/cold_test_df.csv')\n",
    "movies_vector_std = pd.read_csv('../data/processed/movies_vector_std.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
